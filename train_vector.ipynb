{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random , os #, cv2  , time \n",
    "\n",
    "model_name_save = '10x20-4l'\n",
    "model_name_load = '10x20-4l'\n",
    "    \n",
    "folder = \"model\\ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = open('out_data_vector2.txt','r')\n",
    "out_data = eval( b.read())\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "out=[]\n",
    "\n",
    "for i in range(1332):\n",
    "    line=[]\n",
    "    for j in range(1332):\n",
    "        line+=[0]\n",
    "    line[i]=1\n",
    "    data.append(line)        \n",
    "    out.append(out_data[i])         \n",
    "\n",
    "y= np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer :\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights = 0.1 * np.random.rand(n_inputs,n_neurons)-0.05\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "class activation :\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "class activation_softmax:\n",
    "    def forward(self,inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,keepdims=True))\n",
    "        probabilities = exp_values/np.sum(exp_values, axis=1,keepdims=True)\n",
    "        self.output = probabilities\n",
    "class Loss:\n",
    "\n",
    "    def calculate (self,output,y):\n",
    "        sample_losses = self.forward(output,y)\n",
    "        data_loss=np.mean(sample_losses)\n",
    "        return data_loss\n",
    "class Loss_C(Loss):\n",
    "    def forward(self,y_pred,y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7,1-1e-7)\n",
    "        if len(y_true.shape)==1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "        elif len(y_true.shape)==2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "        negetive_log_likelhoods = -np.log(correct_confidences+0.000000000000000001)\n",
    "        #negetive_log_likelhoods = correct_confidences\n",
    "        return negetive_log_likelhoods\n",
    "\n",
    "class Loss_C2(Loss):\n",
    "    \n",
    "    def forward(self,y_pred,y_true):\n",
    "        \n",
    "        samples = len(y_pred)\n",
    "        return (np.abs(y_pred-y_true).sum()) / samples\n",
    "        outputlen = len(y_pred[0])\n",
    "        loss_n = 0\n",
    "        for i in range (samples):\n",
    "            for j in range (outputlen):\n",
    "                loss_n += abs(y_pred[i][j]-y_true[i][j])\n",
    "\n",
    "                \n",
    "        return loss_n / samples\n",
    "def save ():\n",
    "    w1=open(folder+'best_layer1_weights'+model_name_save+'.npy','wb')\n",
    "    b1=open(folder+'best_layer1_biases'+model_name_save+'.npy','wb')\n",
    "    w2=open(folder+'best_layer2_weights'+model_name_save+'.npy','wb')\n",
    "    b2=open(folder+'best_layer2_biases'+model_name_save+'.npy','wb')\n",
    "    w3=open(folder+'best_layer3_weights'+model_name_save+'.npy','wb')\n",
    "    b3=open(folder+'best_layer3_biases'+model_name_save+'.npy','wb')\n",
    "    w4=open(folder+'best_layer4_weights'+model_name_save+'.npy','wb')\n",
    "    b4=open(folder+'best_layer4_biases'+model_name_save+'.npy','wb')\n",
    "\n",
    "    best_loss_file = open(folder+'best_loss'+model_name_save+'.txt','w')\n",
    "    best_loss_file.write(str(best_loss))\n",
    "    best_loss_file.close()\n",
    "\n",
    "    np.save(w1, best_layer1_weights.copy() )\n",
    "    np.save(b1, best_layer1_biases.copy()  )\n",
    "    np.save(w2, best_layer2_weights.copy() )\n",
    "    np.save(b2, best_layer2_biases.copy()  )\n",
    "    np.save(w3, best_layer3_weights.copy() )\n",
    "    np.save(b3, best_layer3_biases.copy()  )\n",
    "    np.save(w4, best_layer4_weights.copy() )\n",
    "    np.save(b4, best_layer4_biases.copy()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer1 = Layer(1332,100)\n",
    "layer2 = Layer(100,20)\n",
    "layer3 = Layer(20,100)\n",
    "layer4 = Layer(100,1332)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best weights loaded ☻\n",
      "OK !\n",
      "\n",
      "rv :  0\n",
      "loss :  79.22067502387614 \n",
      "delta loss :  999919.7793249761\n",
      "0    rv :  0.003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load last weights\n",
    "try :\n",
    "    best_loss = 999999\n",
    "    w1=open(folder+'best_layer1_weights'+model_name_load+'.npy','rb')\n",
    "    b1=open(folder+'best_layer1_biases'+model_name_load+'.npy','rb' )\n",
    "    w2=open(folder+'best_layer2_weights'+model_name_load+'.npy','rb')\n",
    "    b2=open(folder+'best_layer2_biases'+model_name_load+'.npy','rb' )\n",
    "    w3=open(folder+'best_layer3_weights'+model_name_load+'.npy','rb')\n",
    "    b3=open(folder+'best_layer3_biases'+model_name_load+'.npy','rb' )\n",
    "    w4=open(folder+'best_layer4_weights'+model_name_load+'.npy','rb')\n",
    "    b4=open(folder+'best_layer4_biases'+model_name_load+'.npy','rb' )\n",
    "    \n",
    "    layer1.weights = np.load(w1 , allow_pickle=True)\n",
    "    layer1.biases  = np.load(b1 , allow_pickle=True)\n",
    "    layer2.weights = np.load(w2 , allow_pickle=True)\n",
    "    layer2.biases  = np.load(b2 , allow_pickle=True)\n",
    "    layer3.weights = np.load(w3 , allow_pickle=True)\n",
    "    layer3.biases  = np.load(b3 , allow_pickle=True)\n",
    "    layer4.weights = np.load(w4 , allow_pickle=True)\n",
    "    layer4.biases  = np.load(b4 , allow_pickle=True)\n",
    "    print('best weights loaded ☻')\n",
    "    print('OK !')\n",
    "\n",
    "except Exception as er:\n",
    "    print(er, '\\n making new model or loss ...')\n",
    "\n",
    "activation1=activation()\n",
    "activation2=activation()\n",
    "activation3=activation()\n",
    "activation4=activation()\n",
    "loss_function = Loss_C2()\n",
    "\n",
    "best_layer1_weights = layer1.weights.copy()\n",
    "best_layer1_biases  = layer1.biases.copy()\n",
    "best_layer2_weights = layer2.weights.copy()\n",
    "best_layer2_biases  = layer2.biases.copy() \n",
    "best_layer3_weights = layer3.weights.copy()\n",
    "best_layer3_biases  = layer3.biases.copy() \n",
    "best_layer4_weights = layer4.weights.copy()\n",
    "best_layer4_biases  = layer4.biases.copy() \n",
    "\n",
    "lr=0.003\n",
    "\n",
    "best_loss +=0.00000000000001\n",
    "rv= 0\n",
    "for i in range(100):\n",
    "    #print(i)\n",
    "    \n",
    "    layer1.weights += rv * np.random.rand(1332,100)-rv/2\n",
    "    layer1.biases  += rv * np.random.rand(1,100)-rv/2\n",
    "    layer2.weights += rv * np.random.rand(100,20)-rv/2\n",
    "    layer2.biases  += rv * np.random.rand(1,20)-rv/2\n",
    "    layer3.weights += rv * np.random.rand(20,100)-rv/2\n",
    "    layer3.biases  += rv * np.random.rand(1,100)-rv/2\n",
    "    layer4.weights += rv * np.random.rand(100,1332)-rv/2\n",
    "    layer4.biases  += rv * np.random.rand(1,1332)-rv/2\n",
    "    \n",
    "    layer1.forward(data)\n",
    "    activation1.forward(layer1.output)\n",
    "\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "\n",
    "    layer3.forward(activation2.output)\n",
    "    activation3.forward(layer3.output)\n",
    "\n",
    "    layer4.forward(activation3.output)\n",
    "\n",
    "    #activation4.forward(layer4.output)\n",
    "\n",
    "    #print(activation2.output)\n",
    "    #print(y)\n",
    "    #predictions = np.argmax(activation4.output,axis=1)\n",
    "    #acc = np.mean(predictions==y)\n",
    "    #print(predictions)\n",
    "    \n",
    "    loss = loss_function.calculate(layer4.output,y)\n",
    "    #print('loss : ',loss , rv)\n",
    "    \n",
    "    if loss<best_loss:\n",
    "        print('\\nrv : ' , rv)\n",
    "        rv= lr\n",
    "        \n",
    "        print('loss : ',loss,'\\ndelta loss : ',best_loss-loss)\n",
    "        save()\n",
    "        best_layer1_weights = layer1.weights.copy()\n",
    "        best_layer1_biases  = layer1.biases.copy()\n",
    "        best_layer2_weights = layer2.weights.copy()\n",
    "        best_layer2_biases  = layer2.biases.copy()         \n",
    "        best_layer3_weights = layer3.weights.copy()\n",
    "        best_layer3_biases  = layer3.biases.copy()         \n",
    "        best_layer4_weights = layer4.weights.copy()\n",
    "        best_layer4_biases  = layer4.biases.copy()         \n",
    "        best_loss = loss\n",
    "    else:\n",
    "        rv -= rv/30\n",
    "        layer1.weights = best_layer1_weights.copy()\n",
    "        layer1.biases  = best_layer1_biases.copy()\n",
    "        layer2.weights = best_layer2_weights.copy()\n",
    "        layer2.biases  = best_layer2_biases.copy()\n",
    "        layer3.weights = best_layer3_weights.copy()\n",
    "        layer3.biases  = best_layer3_biases.copy()\n",
    "        layer4.weights = best_layer4_weights.copy()\n",
    "        layer4.biases  = best_layer4_biases.copy()\n",
    "    if i %200==0:\n",
    "        print(i,'   rv : ' , rv)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
